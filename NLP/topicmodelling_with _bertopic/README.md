# Introduction
Topic modelling is a techinque in machine learning where unstructured text or articles are classsifed based on semantics.

 Anytime you are using a well built search engine you can now search text based on *meaning*, identify the sentiment of text, extract entities, and much more.
 
 Transformers are behind much of this. These transformers are (unfortunately) not Michael Bay's Autobots and Decepticons and (fortunately) not buzzing electrical boxes. Our NLP transformers lie somewhere in the middle, they're not sentient Autobots (yet), but they can understand language in a way that existed only in sci-fi until a short few years ago.

 We will be using the BERTopic package.A tool in python that does the automatic clustering of data into particular topics.
 
 BERTopic takes advantage of the superior language capabilities of these (not yet sentient) transformer models and uses some other ML magic like UMAP and HDBSCAN to produce what is one of the most advanced techniques in language topic modeling today.

I have linked the kaggle notebooks to this repository so you can also try it out for yourself.
This particular example involved topic modelling for the first half of the 2022 year. Classifying and identifying what the most common notebook topics were from January 1st 2022 to 30th June 2022